+++
date = '2025-09-17T00:00:00-05:00'
draft = false
title = "Markov Chain Monte Carlo (MCMC)"
+++

**Metropolis-Hashtings Algorithm** is a Markov Chain Monte Carlo (MCMC) method for obtaining a sequence
of random samples which converge to being distributed according to a target probability distribution
for which direct sampling is difficult.

# Introduction

This article assumes the reader understands the following:
- Markov Chains & its properties:
  - ergodic property
  - stationary distribution
  - detailed balanced
- Monte Carlo Methods

## Problem:

- approximate or sample from target distribution ğœ‹

## Solution:

- Markov Chain idea: given an ergodic transition matrix ğ‘‡ there exists a stationary distribution ğœ‹
- Metropolis Algorithm idea: given a target distribution ğœ‹ construct an ergodic transition matrix ğ‘‡ that will produce ğœ‹
  - the ergodic theorem states that sampling from this Markov chain ğ‘‡ will approximate the target distribution ğœ‹

## Metropolis Algorithm:

1. given current state ğ‘¥, sample next state ğ‘¥' from a proposal distribution ğ(ğ‘¥ â†’ ğ‘¥')
2. accept next state ğ‘¥' with acceptance probability ğ€(ğ‘¥ â†’ ğ‘¥')
    - if accepted, move to ğ‘¥'
    - otherwise stay at ğ‘¥
3. repeat ğ‘› number of times

From the algorithm, the transition function ğ‘‡ is defined as:

if ğ‘¥ â‰  ğ‘¥':
- $ğ‘‡(ğ‘¥ â†’ ğ‘¥') = ğ(ğ‘¥ â†’ ğ‘¥')ğ€(ğ‘¥ â†’ ğ‘¥')$

if ğ‘¥ = ğ‘¥':
- $ğ‘‡(ğ‘¥ â†’ ğ‘¥) = ğ(ğ‘¥ â†’ ğ‘¥) + ğ›´_{ğ‘¥â‰ ğ‘¥'} [ğ(ğ‘¥ â†’ ğ‘¥')(1 - ğ€(ğ‘¥ â†’ ğ‘¥'))]$

construct acceptance probability ğ€ such that detailed balance holds for ğ‘‡ 
(detailed balance implies stationary distribution, and thus the ergodic theorem above applies):

1. $ğœ‹(ğ‘¥')ğ‘‡(ğ‘¥' â†’ ğ‘¥) = ğœ‹(ğ‘¥)ğ‘‡(ğ‘¥ â†’ ğ‘¥')$
2. $ğœ‹(ğ‘¥')ğ(ğ‘¥' â†’ ğ‘¥)ğ€(ğ‘¥' â†’ ğ‘¥) = ğœ‹(ğ‘¥)ğ(ğ‘¥ â†’ ğ‘¥')ğ€(ğ‘¥ â†’ ğ‘¥')$
3. $\frac{ğ€(ğ‘¥ â†’ ğ‘¥')}{ğ€(ğ‘¥' â†’ ğ‘¥)} = \frac{ğœ‹(ğ‘¥')ğ(ğ‘¥' â†’ ğ‘¥)}{ğœ‹(ğ‘¥)ğ(ğ‘¥ â†’ ğ‘¥')}$
4. $ğ€(ğ‘¥ â†’ ğ‘¥') = ğ‘šğ‘–ğ‘›(1, \frac{ğœ‹(ğ‘¥')ğ(ğ‘¥' â†’ ğ‘¥)}{ğœ‹(ğ‘¥)ğ(ğ‘¥ â†’ ğ‘¥')})$
5. $ğ€(ğ‘¥ â†’ ğ‘¥') = ğ‘šğ‘–ğ‘›(1, \frac{\frac{ğœ‹'(ğ‘¥')}{ğ‘} ğ(ğ‘¥' â†’ ğ‘¥)}{\frac{ğœ‹'(ğ‘¥)}{ğ‘} ğ(ğ‘¥ â†’ ğ‘¥')})$
6. $ğ€(ğ‘¥ â†’ ğ‘¥') = ğ‘šğ‘–ğ‘›(1, \frac{ğœ‹'(ğ‘¥') ğ(ğ‘¥' â†’ ğ‘¥)}{ğœ‹'(ğ‘¥) ğ(ğ‘¥ â†’ ğ‘¥')})$

1 by definition of detailed balanced

5 because ğœ‹(ğ‘¥) is assumed to be hard to compute because of its normalizing constant 1/ğ‘, we can rewrite it as $ğœ‹(ğ‘¥) = \frac{ğœ‹'(ğ‘¥)}{ğ‘}$

6 the normalizing constants are cancelled out, rendering ğ€(ğ‘¥ â†’ ğ‘¥') to be easy to compute



# Choice of Proposal Distribution ğ

ğ must be reversible:
- ğ(ğ‘¥' â†’ ğ‘¥) > 0 implies ğ(ğ‘¥ â†’ ğ‘¥') > 0

opposing forces:
- ğ should be spread out to improve mixing
- but then acceptance probability will be low, which in turn slows down mixing

## Random Walk Metropolis

If ğ is chosen to be symmetric (i.e. ğ(ğ‘¥ â†’ ğ‘¥') = ğ(ğ‘¥' â†’ ğ‘¥) for all ğ‘¥' and ğ‘¥), then the acceptance probability ğ€ becomes:
- $ğ€(ğ‘¥ â†’ ğ‘¥') = ğ‘šğ‘–ğ‘›(1, \frac{ğœ‹(ğ‘¥')ğ(ğ‘¥'â†’ ğ‘¥)}{ğœ‹(ğ‘¥)ğ(ğ‘¥ â†’ ğ‘¥')})$
- $ğ€(ğ‘¥ â†’ ğ‘¥') = ğ‘šğ‘–ğ‘›(1, \frac{ğœ‹(ğ‘¥')}{ğœ‹(ğ‘¥)})$

now:

- if ğ‘¥' has density greater than or equal to ğ‘¥'s density (i.e. ğœ‹(ğ‘¥') â‰¥ ğœ‹(ğ‘¥)) then we will always accept ğ‘¥'
- if ğ‘¥' has density less than ğ‘¥'s density (i.e. ğœ‹(ğ‘¥') < ğœ‹(ğ‘¥)) then we will always accept ğ‘¥' with probability $\frac{ğœ‹(ğ‘¥')}{ğœ‹(ğ‘¥)}$

## Independent Metropolis-Hastings Proposal

If ğ is chosen to be independent (i.e. ğ(ğ‘¥ â†’ ğ‘¥') = ğ(ğ‘¥')), then the acceptance probability becomes:

- $ğ€(ğ‘¥ â†’ ğ‘¥') = ğ‘šğ‘–ğ‘›(1, \frac{ğœ‹(ğ‘¥')ğ(ğ‘¥'â†’ ğ‘¥)}{ğœ‹(ğ‘¥)ğ(ğ‘¥ â†’ ğ‘¥')})$
- $ğ€(ğ‘¥ â†’ ğ‘¥') = ğ‘šğ‘–ğ‘›(1, \frac{ğœ‹(ğ‘¥')ğ(ğ‘¥)}{ğœ‹(ğ‘¥)ğ(ğ‘¥')})$

# Resources

- [YouTube - Very Normal](https://www.youtube.com/watch?v=Jr1GdNI3Vfo)
- [YouTube - mathematicalmonk](https://www.youtube.com/watch?v=gxHe9wAWuGQ)
- [YouTube - Jarad Niemi](https://www.youtube.com/watch?v=VGRVRjr0vyw)
- [YouTube - Kapil Sachdeva](https://www.youtube.com/watch?v=oX2wIGSn4jY)
- [Coursera - Probabilistic Graphical Models 2](https://www.coursera.org/lecture/probabilistic-graphical-models-2-inference/metropolis-hastings-algorithm-UPVWC)
